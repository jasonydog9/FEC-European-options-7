{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Trained Models for Streamlit App\n",
    "\n",
    "This notebook trains and saves the ML models for use in the Streamlit web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING DATA\n",
      "======================================================================\n",
      "\n",
      "Training set: 1,982,775 samples\n",
      "Features: ['T_years', 'moneyness', 'risk_free_rate']\n",
      "\n",
      "✅ Data loaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load training data\n",
    "X_train = pd.read_csv('../data/model_input/X_train.csv')\n",
    "y_train = pd.read_csv('../data/model_input/y_train.csv').iloc[:, 0]\n",
    "\n",
    "print(f\"\\nTraining set: {len(X_train):,} samples\")\n",
    "print(f\"Features: {list(X_train.columns)}\")\n",
    "print(\"\\n✅ Data loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING RANDOM FOREST\n",
      "======================================================================\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   20.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Random Forest trained!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   55.1s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TRAINING RANDOM FOREST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"\\n✅ Random Forest trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING XGBOOST\n",
      "======================================================================\n",
      "\n",
      "Training...\n",
      "\n",
      "✅ XGBoost trained!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TRAINING XGBOOST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining...\")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"\\n✅ XGBoost trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SAVING MODELS\n",
      "======================================================================\n",
      "\n",
      "Created directory: ../models\n",
      "\n",
      "✅ Random Forest saved to: ../models/rf_model.pkl\n",
      "✅ XGBoost saved to: ../models/xgb_model.pkl\n",
      "\n",
      "Model file sizes:\n",
      "  Random Forest: 724.99 MB\n",
      "  XGBoost: 2.55 MB\n",
      "\n",
      "======================================================================\n",
      "✅ MODELS SAVED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n",
      "You can now run the Streamlit app with:\n",
      "  streamlit run app.py\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SAVING MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create models directory\n",
    "model_dir = '../models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    print(f\"\\nCreated directory: {model_dir}\")\n",
    "\n",
    "# Save Random Forest\n",
    "rf_path = os.path.join(model_dir, 'rf_model.pkl')\n",
    "with open(rf_path, 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "print(f\"\\n✅ Random Forest saved to: {rf_path}\")\n",
    "\n",
    "# Save XGBoost\n",
    "xgb_path = os.path.join(model_dir, 'xgb_model.pkl')\n",
    "with open(xgb_path, 'wb') as f:\n",
    "    pickle.dump(xgb_model, f)\n",
    "print(f\"✅ XGBoost saved to: {xgb_path}\")\n",
    "\n",
    "# Check file sizes\n",
    "rf_size = os.path.getsize(rf_path) / (1024 * 1024)  # MB\n",
    "xgb_size = os.path.getsize(xgb_path) / (1024 * 1024)  # MB\n",
    "\n",
    "print(f\"\\nModel file sizes:\")\n",
    "print(f\"  Random Forest: {rf_size:.2f} MB\")\n",
    "print(f\"  XGBoost: {xgb_size:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ MODELS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nYou can now run the Streamlit app with:\")\n",
    "print(\"  streamlit run app.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Models Load Correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERIFYING MODEL LOADING\n",
      "======================================================================\n",
      "\n",
      "✅ Random Forest loaded successfully\n",
      "✅ XGBoost loaded successfully\n",
      "\n",
      "Test prediction (30 days, 97.5% moneyness, 2% rate):\n",
      "  Random Forest IV: -55.32%\n",
      "  XGBoost IV: -69.47%\n",
      "\n",
      "======================================================================\n",
      "✅ ALL TESTS PASSED!\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"VERIFYING MODEL LOADING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Try loading the models\n",
    "try:\n",
    "    with open(rf_path, 'rb') as f:\n",
    "        rf_loaded = pickle.load(f)\n",
    "    print(\"\\n✅ Random Forest loaded successfully\")\n",
    "    \n",
    "    with open(xgb_path, 'rb') as f:\n",
    "        xgb_loaded = pickle.load(f)\n",
    "    print(\"✅ XGBoost loaded successfully\")\n",
    "    \n",
    "    # Test predictions\n",
    "    test_input = pd.DataFrame({\n",
    "        'T_years': [0.0833],  # 30 days\n",
    "        'moneyness': [0.975],  # Slightly OTM\n",
    "        'risk_free_rate': [0.02]\n",
    "    })\n",
    "    \n",
    "    rf_pred = rf_loaded.predict(test_input)[0]\n",
    "    xgb_pred = xgb_loaded.predict(test_input)[0]\n",
    "    \n",
    "    print(f\"\\nTest prediction (30 days, 97.5% moneyness, 2% rate):\")\n",
    "    print(f\"  Random Forest IV: {rf_pred*100:.2f}%\")\n",
    "    print(f\"  XGBoost IV: {xgb_pred*100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✅ ALL TESTS PASSED!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error loading models: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
