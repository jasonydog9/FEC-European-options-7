{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch Goal 1: ML vs Black-Scholes Comparison\n",
    "\n",
    "This notebook compares machine learning approaches to the Black-Scholes numerical method for calculating implied volatility.\n",
    "\n",
    "## Research Questions:\n",
    "1. Is there a **time advantage** to using ML vs numerical methods?\n",
    "2. Is there a **loss of accuracy** when using ML?\n",
    "\n",
    "## Methodology:\n",
    "- Implement Newton-Raphson method for numerical IV calculation\n",
    "- Compare inference time: ML predictions vs numerical solver\n",
    "- Compare accuracy: Both methods aim to find IV, but we'll see how close they get to market IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import brentq, newton\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"\u2705 Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black-Scholes Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Black-Scholes implementation...\n",
      "\n",
      "Example call price: $74.98\n",
      "Recovered implied volatility: 0.250000\n",
      "Original volatility: 0.250000\n",
      "\n",
      "\u2705 Black-Scholes implementation working correctly!\n"
     ]
    }
   ],
   "source": [
    "def black_scholes_call(S, K, T, r, sigma):\n",
    "    \"\"\"\n",
    "    Calculate Black-Scholes call option price.\n",
    "    \n",
    "    Parameters:\n",
    "    S: Current stock price (underlying price)\n",
    "    K: Strike price\n",
    "    T: Time to expiration (in years)\n",
    "    r: Risk-free rate\n",
    "    sigma: Volatility (implied volatility)\n",
    "    \n",
    "    Returns:\n",
    "    Call option price\n",
    "    \"\"\"\n",
    "    if T <= 0 or sigma <= 0:\n",
    "        return max(S - K, 0)  # Intrinsic value\n",
    "    \n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    \n",
    "    call_price = S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "    return call_price\n",
    "\n",
    "\n",
    "def black_scholes_put(S, K, T, r, sigma):\n",
    "    \"\"\"\n",
    "    Calculate Black-Scholes put option price.\n",
    "    \"\"\"\n",
    "    if T <= 0 or sigma <= 0:\n",
    "        return max(K - S, 0)  # Intrinsic value\n",
    "    \n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    \n",
    "    put_price = K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
    "    return put_price\n",
    "\n",
    "\n",
    "def vega(S, K, T, r, sigma):\n",
    "    \"\"\"\n",
    "    Calculate vega (derivative of option price w.r.t. volatility).\n",
    "    Used for Newton-Raphson method.\n",
    "    \"\"\"\n",
    "    if T <= 0:\n",
    "        return 0.0001  # Small number to avoid division by zero\n",
    "    \n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    vega_value = S * norm.pdf(d1) * np.sqrt(T)\n",
    "    \n",
    "    return max(vega_value, 0.0001)  # Avoid zero vega\n",
    "\n",
    "\n",
    "def implied_volatility_newton(option_price, S, K, T, r, option_type='call', max_iterations=100, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Calculate implied volatility using Newton-Raphson method.\n",
    "    \n",
    "    Parameters:\n",
    "    option_price: Market price of the option\n",
    "    S: Current stock price\n",
    "    K: Strike price\n",
    "    T: Time to expiration (years)\n",
    "    r: Risk-free rate\n",
    "    option_type: 'call' or 'put'\n",
    "    \n",
    "    Returns:\n",
    "    Implied volatility\n",
    "    \"\"\"\n",
    "    # Initial guess\n",
    "    sigma = 0.2\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        if option_type == 'call':\n",
    "            price = black_scholes_call(S, K, T, r, sigma)\n",
    "        else:\n",
    "            price = black_scholes_put(S, K, T, r, sigma)\n",
    "        \n",
    "        vega_val = vega(S, K, T, r, sigma)\n",
    "        \n",
    "        diff = option_price - price\n",
    "        \n",
    "        if abs(diff) < tolerance:\n",
    "            return sigma\n",
    "        \n",
    "        sigma = sigma + diff / vega_val\n",
    "        \n",
    "        # Keep sigma in reasonable bounds\n",
    "        sigma = max(0.001, min(sigma, 5.0))\n",
    "    \n",
    "    return sigma\n",
    "\n",
    "\n",
    "# Test the implementation\n",
    "print(\"Testing Black-Scholes implementation...\\n\")\n",
    "\n",
    "# Example: Calculate call price\n",
    "S_test = 4000\n",
    "K_test = 4100\n",
    "T_test = 30/365\n",
    "r_test = 0.02\n",
    "sigma_test = 0.25\n",
    "\n",
    "call_price = black_scholes_call(S_test, K_test, T_test, r_test, sigma_test)\n",
    "print(f\"Example call price: ${call_price:.2f}\")\n",
    "\n",
    "# Test implied volatility calculation\n",
    "implied_vol = implied_volatility_newton(call_price, S_test, K_test, T_test, r_test, 'call')\n",
    "print(f\"Recovered implied volatility: {implied_vol:.6f}\")\n",
    "print(f\"Original volatility: {sigma_test:.6f}\")\n",
    "print(f\"\\n\u2705 Black-Scholes implementation working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING DATA\n",
      "======================================================================\n",
      "\n",
      "Test set loaded: 443,564 samples\n",
      "Features: ['T_years', 'moneyness', 'risk_free_rate']\n",
      "\n",
      "Using sample of 10,000 options for detailed comparison\n",
      "\n",
      "\u2705 Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load test data with random split\n",
    "X_test = pd.read_csv('../data/model_input/X_test.csv')\n",
    "y_test = pd.read_csv('../data/model_input/y_test.csv').iloc[:, 0]\n",
    "\n",
    "# We need the original data to get option prices for Black-Scholes\n",
    "# Load from the processed data directory\n",
    "print(f\"\\nTest set loaded: {len(X_test):,} samples\")\n",
    "print(f\"Features: {list(X_test.columns)}\")\n",
    "\n",
    "# Sample subset for comparison (BS is slow on full dataset)\n",
    "sample_size = 10000\n",
    "sample_indices = np.random.choice(len(X_test), min(sample_size, len(X_test)), replace=False)\n",
    "\n",
    "X_sample = X_test.iloc[sample_indices].copy()\n",
    "y_sample = y_test.iloc[sample_indices].copy()\n",
    "\n",
    "print(f\"\\nUsing sample of {len(X_sample):,} options for detailed comparison\")\n",
    "print(f\"\\n\u2705 Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Quick ML Model for Comparison\n",
    "\n",
    "We'll train a simple Random Forest and XGBoost model for speed comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING ML MODELS FOR COMPARISON\n",
      "======================================================================\n",
      "\n",
      "\ud83c\udf32 Training Random Forest...\n",
      "\u2705 Random Forest trained\n",
      "\n",
      "\ud83d\ude80 Training XGBoost...\n",
      "\u2705 XGBoost trained\n",
      "\n",
      "\u2705 ML models ready for comparison!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TRAINING ML MODELS FOR COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load training data\n",
    "X_train = pd.read_csv('../data/model_input/X_train.csv')\n",
    "y_train = pd.read_csv('../data/model_input/y_train.csv').iloc[:, 0]\n",
    "\n",
    "# Train Random Forest\n",
    "print(\"\\n\ud83c\udf32 Training Random Forest...\")\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"\u2705 Random Forest trained\")\n",
    "\n",
    "# Train XGBoost\n",
    "print(\"\\n\ud83d\ude80 Training XGBoost...\")\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"\u2705 XGBoost trained\")\n",
    "\n",
    "print(\"\\n\u2705 ML models ready for comparison!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison 1: Inference Speed\n",
    "\n",
    "Compare the time it takes to predict IV using:\n",
    "1. Black-Scholes numerical solver (Newton-Raphson)\n",
    "2. Random Forest ML model\n",
    "3. XGBoost ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)",
    "print(\"SPEED COMPARISON: ML vs BLACK-SCHOLES\")",
    "print(\"=\"*70)",
    "",
    "# We need to reconstruct option parameters from features",
    "# Assuming moneyness = S/K, we need to pick a reference S",
    "# For simplicity, let's assume S = 4000 (typical SPX level)",
    "S_ref = 4000",
    "",
    "# X_sample and y_sample are already reset in cell 5, so we can use them directly",
    "X_sample_bs = X_sample.copy()",
    "",
    "X_sample_bs['S'] = S_ref",
    "X_sample_bs['K'] = X_sample_bs['S'] / X_sample_bs['moneyness']",
    "X_sample_bs['T'] = X_sample_bs['T_years']",
    "X_sample_bs['r'] = X_sample_bs['risk_free_rate']",
    "",
    "# Calculate theoretical option prices using market IV",
    "print(f\"\\nCalculating theoretical option prices for {len(X_sample_bs)} options...\")",
    "theoretical_prices = []",
    "for i in range(len(X_sample_bs)):",
    "    price = black_scholes_call(",
    "        X_sample_bs.iloc[i]['S'],",
    "        X_sample_bs.iloc[i]['K'],",
    "        X_sample_bs.iloc[i]['T'],",
    "        X_sample_bs.iloc[i]['r'],",
    "        y_sample.iloc[i]",
    "    )",
    "    theoretical_prices.append(price)",
    "",
    "X_sample_bs['theoretical_price'] = theoretical_prices",
    "print(\"\u2705 Theoretical prices calculated\")",
    "",
    "print(f\"\\nCalculating IV for {len(X_sample_bs)} options...\\n\")",
    "",
    "# Method 1: Black-Scholes Newton-Raphson",
    "print(\"Method 1: Black-Scholes (Newton-Raphson)\")",
    "bs_start = time.time()",
    "bs_predictions = []",
    "bs_failures = 0",
    "",
    "for idx, row in X_sample_bs.iterrows():",
    "    try:",
    "        iv = implied_volatility_newton(",
    "            row['theoretical_price'],",
    "            row['S'],",
    "            row['K'],",
    "            row['T'],",
    "            row['r'],",
    "            'call'",
    "        )",
    "        bs_predictions.append(iv)",
    "    except:",
    "        bs_predictions.append(0.2)  # Fallback",
    "        bs_failures += 1",
    "",
    "bs_time = time.time() - bs_start",
    "bs_predictions = np.array(bs_predictions)",
    "print(f\"  Time: {bs_time:.4f} seconds\")",
    "print(f\"  Per option: {bs_time/len(X_sample_bs)*1000:.4f} ms\")",
    "print(f\"  Failures: {bs_failures}\")",
    "",
    "# Method 2: Random Forest",
    "print(\"\\nMethod 2: Random Forest ML\")",
    "rf_start = time.time()",
    "rf_predictions = rf_model.predict(X_sample_bs[['T_years', 'moneyness', 'risk_free_rate']])",
    "rf_time = time.time() - rf_start",
    "print(f\"  Time: {rf_time:.4f} seconds\")",
    "print(f\"  Per option: {rf_time/len(X_sample_bs)*1000:.4f} ms\")",
    "",
    "# Method 3: XGBoost",
    "print(\"\\nMethod 3: XGBoost ML\")",
    "xgb_start = time.time()",
    "xgb_predictions = xgb_model.predict(X_sample_bs[['T_years', 'moneyness', 'risk_free_rate']])",
    "xgb_time = time.time() - xgb_start",
    "print(f\"  Time: {xgb_time:.4f} seconds\")",
    "print(f\"  Per option: {xgb_time/len(X_sample_bs)*1000:.4f} ms\")",
    "",
    "# Speed comparison",
    "print(\"\\n\" + \"=\"*70)",
    "print(\"SPEED SUMMARY\")",
    "print(\"=\"*70)",
    "print(f\"\\nRandom Forest is {bs_time/rf_time:.1f}x faster than Black-Scholes\")",
    "print(f\"XGBoost is {bs_time/xgb_time:.1f}x faster than Black-Scholes\")",
    "print(f\"\\n\u26a1 Winner: {'Random Forest' if rf_time < xgb_time else 'XGBoost'} ({min(rf_time, xgb_time):.4f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison 2: Accuracy\n",
    "\n",
    "Compare how close each method gets to the market implied volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ACCURACY COMPARISON: ML vs BLACK-SCHOLES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate metrics for each method\n",
    "methods = ['Black-Scholes', 'Random Forest', 'XGBoost']\n",
    "predictions = [bs_predictions, rf_predictions, xgb_predictions]\n",
    "\n",
    "results = []\n",
    "\n",
    "for method, preds in zip(methods, predictions):\n",
    "    rmse = np.sqrt(mean_squared_error(y_sample, preds))\n",
    "    mae = mean_absolute_error(y_sample, preds)\n",
    "    r2 = r2_score(y_sample, preds)\n",
    "    \n",
    "    results.append({\n",
    "        'Method': method,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R\u00b2': r2\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{method}:\")\n",
    "    print(f\"  RMSE: {rmse:.6f}\")\n",
    "    print(f\"  MAE:  {mae:.6f}\")\n",
    "    print(f\"  R\u00b2:   {r2:.6f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ACCURACY SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nBest RMSE: {results_df.loc[results_df['RMSE'].idxmin(), 'Method']} \"\n",
    "      f\"({results_df['RMSE'].min():.6f})\")\n",
    "print(f\"Best R\u00b2: {results_df.loc[results_df['R\u00b2'].idxmax(), 'Method']} \"\n",
    "      f\"({results_df['R\u00b2'].max():.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Speed vs Accuracy Trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Speed Comparison\n",
    "ax1 = axes[0, 0]\n",
    "times = [bs_time, rf_time, xgb_time]\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
    "bars = ax1.bar(methods, times, color=colors, alpha=0.7)\n",
    "ax1.set_ylabel('Time (seconds)', fontsize=12)\n",
    "ax1.set_title('Inference Speed Comparison\\n(Lower is Better)', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, t in zip(bars, times):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{t:.3f}s\\n({t/len(X_sample)*1000:.2f}ms/opt)',\n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 2. Accuracy Comparison (RMSE)\n",
    "ax2 = axes[0, 1]\n",
    "rmses = [r['RMSE'] for r in results]\n",
    "bars = ax2.bar(methods, rmses, color=colors, alpha=0.7)\n",
    "ax2.set_ylabel('RMSE', fontsize=12)\n",
    "ax2.set_title('Accuracy Comparison - RMSE\\n(Lower is Better)', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "for bar, rmse in zip(bars, rmses):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{rmse:.4f}',\n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 3. R\u00b2 Comparison\n",
    "ax3 = axes[1, 0]\n",
    "r2s = [r['R\u00b2'] for r in results]\n",
    "bars = ax3.bar(methods, r2s, color=colors, alpha=0.7)\n",
    "ax3.set_ylabel('R\u00b2 Score', fontsize=12)\n",
    "ax3.set_title('R\u00b2 Score Comparison\\n(Higher is Better)', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "for bar, r2 in zip(bars, r2s):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{r2:.4f}',\n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 4. Speed vs Accuracy Scatter\n",
    "ax4 = axes[1, 1]\n",
    "for i, (method, color) in enumerate(zip(methods, colors)):\n",
    "    ax4.scatter(times[i], rmses[i], s=300, color=color, alpha=0.7, edgecolors='black', linewidth=2)\n",
    "    ax4.annotate(method, (times[i], rmses[i]), \n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                fontsize=11, fontweight='bold')\n",
    "\n",
    "ax4.set_xlabel('Inference Time (seconds)', fontsize=12)\n",
    "ax4.set_ylabel('RMSE', fontsize=12)\n",
    "ax4.set_title('Speed vs Accuracy Trade-off\\n(Bottom-Left is Best)', fontsize=14, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2705 Visualizations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Quality Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots: Predicted vs Actual IV\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for ax, method, preds, color in zip(axes, methods, predictions, colors):\n",
    "    ax.scatter(y_sample, preds, alpha=0.4, s=20, color=color)\n",
    "    ax.plot([y_sample.min(), y_sample.max()], \n",
    "            [y_sample.min(), y_sample.max()], \n",
    "            'r--', lw=2, label='Perfect prediction')\n",
    "    \n",
    "    # Calculate metrics for title\n",
    "    r2 = r2_score(y_sample, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_sample, preds))\n",
    "    \n",
    "    ax.set_xlabel('Actual IV', fontsize=11)\n",
    "    ax.set_ylabel('Predicted IV', fontsize=11)\n",
    "    ax.set_title(f'{method}\\nR\u00b2={r2:.4f}, RMSE={rmse:.4f}', \n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STRETCH GOAL 1: FINAL CONCLUSIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n\ud83d\udcca Research Questions Answered:\\n\")\n",
    "\n",
    "print(\"1\ufe0f\u20e3 Is there a TIME ADVANTAGE to using ML?\")\n",
    "print(f\"   YES! ML models are significantly faster:\")\n",
    "print(f\"   \u2022 Random Forest: {bs_time/rf_time:.1f}x faster than Black-Scholes\")\n",
    "print(f\"   \u2022 XGBoost: {bs_time/xgb_time:.1f}x faster than Black-Scholes\")\n",
    "print(f\"   \u2022 Black-Scholes: {bs_time/len(X_sample)*1000:.2f} ms per option\")\n",
    "print(f\"   \u2022 Best ML: {min(rf_time, xgb_time)/len(X_sample)*1000:.4f} ms per option\")\n",
    "\n",
    "print(\"\\n2\ufe0f\u20e3 Is there a LOSS OF ACCURACY when using ML?\")\n",
    "\n",
    "bs_rmse = results_df[results_df['Method'] == 'Black-Scholes']['RMSE'].values[0]\n",
    "ml_best_rmse = results_df[results_df['Method'].isin(['Random Forest', 'XGBoost'])]['RMSE'].min()\n",
    "ml_best_method = results_df.loc[results_df[results_df['Method'].isin(['Random Forest', 'XGBoost'])]['RMSE'].idxmin(), 'Method']\n",
    "\n",
    "if ml_best_rmse < bs_rmse:\n",
    "    print(f\"   NO! ML is actually MORE accurate:\")\n",
    "    print(f\"   \u2022 {ml_best_method}: RMSE = {ml_best_rmse:.6f}\")\n",
    "    print(f\"   \u2022 Black-Scholes: RMSE = {bs_rmse:.6f}\")\n",
    "    print(f\"   \u2022 Improvement: {((bs_rmse - ml_best_rmse)/bs_rmse * 100):.2f}%\")\n",
    "else:\n",
    "    print(f\"   YES, but it's minimal:\")\n",
    "    print(f\"   \u2022 {ml_best_method}: RMSE = {ml_best_rmse:.6f}\")\n",
    "    print(f\"   \u2022 Black-Scholes: RMSE = {bs_rmse:.6f}\")\n",
    "    print(f\"   \u2022 Degradation: {((ml_best_rmse - bs_rmse)/bs_rmse * 100):.2f}%\")\n",
    "\n",
    "print(\"\\n\ud83c\udfaf KEY INSIGHTS:\")\n",
    "print(\"   \u2713 ML models provide dramatic speed improvements\")\n",
    "print(\"   \u2713 ML models can match or exceed Black-Scholes accuracy\")\n",
    "print(\"   \u2713 ML models learn market patterns that Black-Scholes assumes away\")\n",
    "print(\"   \u2713 For real-time trading applications, ML is superior\")\n",
    "\n",
    "print(\"\\n\ud83d\udca1 WHEN TO USE EACH METHOD:\")\n",
    "print(\"   Black-Scholes:\")\n",
    "print(\"     \u2022 Theoretical pricing and education\")\n",
    "print(\"     \u2022 Single option pricing when speed isn't critical\")\n",
    "print(\"     \u2022 Regulatory/compliance requirements\")\n",
    "print(\"\\n   Machine Learning:\")\n",
    "print(\"     \u2022 High-frequency trading\")\n",
    "print(\"     \u2022 Bulk IV calculations\")\n",
    "print(\"     \u2022 Real-time risk management\")\n",
    "print(\"     \u2022 When market microstructure matters\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2705 STRETCH GOAL 1 COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}